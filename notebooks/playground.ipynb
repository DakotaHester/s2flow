{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "806a6211",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timm.models.resnet import resnet101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "acb10e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from typing import Literal\n",
    "\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    \n",
    "    \"\"\"A simple convolutional block followed by batch normalization and ReLU activation.\"\"\"\n",
    "    def __init__(self, \n",
    "        in_channels: int, \n",
    "        out_channels: int, \n",
    "        kernel_size: int=3, \n",
    "        stride: int=1, \n",
    "        padding: int=1, \n",
    "        batch_norm: int=True, \n",
    "        activation: Literal['relu', 'leaky_relu', 'sigmoid', 'softmax', 'tanh', 'swish']='relu',\n",
    "    ):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.batch_norm = batch_norm\n",
    "        self.activation = activation\n",
    "        \n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False)\n",
    "        if batch_norm:\n",
    "            self.bn = nn.BatchNorm2d(out_channels)\n",
    "            \n",
    "        if activation is not None:\n",
    "            if activation == 'relu':\n",
    "                self.act = nn.ReLU(inplace=True)\n",
    "            elif activation == 'gelu':\n",
    "                self.act = nn.GELU()\n",
    "            elif activation == 'leaky_relu':\n",
    "                self.act = nn.LeakyReLU(inplace=True)\n",
    "            elif activation == 'sigmoid':\n",
    "                self.act = nn.Sigmoid()\n",
    "            elif activation == 'softmax':\n",
    "                self.act = nn.Softmax(dim=1)\n",
    "            elif activation == 'tanh':\n",
    "                self.act = nn.Tanh()\n",
    "            elif activation == 'swish':\n",
    "                self.act = nn.SiLU()\n",
    "            else:\n",
    "                raise ValueError(f'Invalid value for `activation`: {activation}. Supported values are [\"relu\", \"leaky_relu\", \"sigmoid\", \"softmax\", \"tanh\"].')\n",
    "    \n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.conv(x)\n",
    "        if self.batch_norm:\n",
    "            x = self.bn(x)\n",
    "        \n",
    "        if self.activation is not None:\n",
    "            x = self.act(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class ASPP(nn.Module):\n",
    "    \"\"\"Atrous Spatial Pyramid Pooling as in DeepLab v3+.\"\"\"\n",
    "    def __init__(self, in_channels: int, out_channels: int, dilation_rates: tuple[int, ...]) -> None:\n",
    "        super().__init__()\n",
    "        # 1Ã—1 conv branch\n",
    "        self.conv_1x1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        # parallel atrous conv branches\n",
    "        self.branches = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=3,\n",
    "                          padding=rate, dilation=rate, bias=False),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.ReLU(inplace=True),\n",
    "            )\n",
    "            for rate in dilation_rates\n",
    "        ])\n",
    "        # image-level pooling branch\n",
    "        self.image_pool = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        # combine & project\n",
    "        self.project = nn.Sequential(\n",
    "            nn.Conv2d(out_channels * (2 + len(dilation_rates)), out_channels, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        size = x.shape[-2:]\n",
    "        feats = [self.conv_1x1(x)] + [branch(x) for branch in self.branches]\n",
    "        # image-level features\n",
    "        img_feat = self.image_pool(x)\n",
    "        img_feat = nn.functional.interpolate(img_feat, size=size, mode=\"bilinear\", align_corners=False)\n",
    "        feats.append(img_feat)\n",
    "        x = torch.cat(feats, dim=1)\n",
    "        return self.project(x)\n",
    "\n",
    "\n",
    "class DepthwiseSeparableConv(nn.Module):\n",
    "    \"\"\"Depthwise separable convolution: depthwise conv + pointwise conv.\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        kernel_size: int = 3,\n",
    "        stride: int = 1,\n",
    "        padding: int = 1,\n",
    "        dilation: int = 1,\n",
    "        bias: bool = False,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        # Depthwise: groups=in_channels\n",
    "        self.depthwise = nn.Conv2d(\n",
    "            in_channels, in_channels, kernel_size,\n",
    "            stride, padding, dilation, groups=in_channels, bias=bias\n",
    "        )\n",
    "        # Pointwise: 1x1 convolution to mix channels\n",
    "        self.pointwise = nn.Conv2d(\n",
    "            in_channels, out_channels, kernel_size=1, bias=bias\n",
    "        )\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.depthwise(x)\n",
    "        x = self.pointwise(x)\n",
    "        x = self.bn(x)\n",
    "        return self.relu(x)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"DeepLab v3+ decoder that fuses low- and high-level features.\"\"\"\n",
    "    def __init__(self, low_level_in: int, low_level_out: int, num_classes: int) -> None:\n",
    "        super().__init__()\n",
    "        # Reduce low-level feature channels to low_level_out (e.g. 48)\n",
    "        self.reduce_low = ConvBlock(low_level_in, low_level_out, kernel_size=1, padding=0, batch_norm=True, activation='relu')\n",
    "        # Two separable conv layers to refine concatenated features\n",
    "        self.refine = nn.Sequential(\n",
    "            DepthwiseSeparableConv(low_level_out + 256, 256, kernel_size=3, padding=1),\n",
    "            DepthwiseSeparableConv(256, 256, kernel_size=3, padding=1),\n",
    "        )\n",
    "        # Final classifier\n",
    "        self.classifier = nn.Conv2d(256, num_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, low_level_feat: torch.Tensor, high_level_feat: torch.Tensor) -> torch.Tensor:\n",
    "        # Upsample ASPP output by factor 4\n",
    "        high = nn.functional.interpolate(high_level_feat, size=low_level_feat.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "        low = self.reduce_low(low_level_feat)\n",
    "        x = torch.cat([low, high], dim=1)\n",
    "        x = self.refine(x)\n",
    "        return self.classifier(x)\n",
    "\n",
    "\n",
    "class DeepLabV3Plus(nn.Module):\n",
    "    \"\"\"\n",
    "    DeepLab v3+ for semantic segmentation.\n",
    "    - backbone: module returning (low_level_feat, high_level_feat)\n",
    "    - num_classes: # of segmentation classes\n",
    "    - aspp_rates: dilation rates for ASPP\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        backbone: nn.Module,\n",
    "        num_classes: int,\n",
    "        aspp_out: int = 256,\n",
    "        aspp_rates: tuple[int, ...] = (12, 24, 36),\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        # ASPP on high-level features\n",
    "        self.aspp = ASPP(in_channels=2048, out_channels=aspp_out, dilation_rates=aspp_rates)\n",
    "        # Decoder fusing ASPP and low-level (conv2) features\n",
    "        self.decoder = Decoder(low_level_in=256, low_level_out=48, num_classes=num_classes)\n",
    "        \n",
    "        if num_classes == 1:\n",
    "            self.activation = nn.Sigmoid()\n",
    "        else:\n",
    "            self.activation = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        low_level, high_level = self.backbone(x)\n",
    "        x = self.aspp(high_level)\n",
    "        x = self.decoder(low_level, x)\n",
    "        # Final upsample to input resolution\n",
    "        x = nn.functional.interpolate(x, size=x.shape[-2]*4, mode=\"bilinear\", align_corners=False)\n",
    "        return self.activation(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3d3ebcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetBackbone(nn.Module):\n",
    "    \"\"\"\n",
    "    Wraps a ResNet-101 to output (low_level_feat, high_level_feat).\n",
    "    output_stride=16: remove stride in layer4; stride=8: also in layer3.\n",
    "    \"\"\"\n",
    "    def __init__(self, output_stride: int = 16, pretrained: bool = True, in_channels=4) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        if isinstance(pretrained, bool):\n",
    "            # resnet = resnet152(weights=ResNet152_Weights.DEFAULT if pretrained else None)\n",
    "            resnet = resnet101(pretrained=pretrained)\n",
    "\n",
    "            if in_channels != 3:\n",
    "                resnet.conv1 = nn.Conv2d(in_channels, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        else:\n",
    "            # resnet = resnet152()\n",
    "            resnet = resnet101()\n",
    "            if in_channels != 3:\n",
    "                resnet.conv1 = nn.Conv2d(in_channels, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "            if pretrained is not None:\n",
    "                resnet.load_state_dict(load_pth(pretrained), strict=True)\n",
    "            \n",
    "        # Modify strides/dilations for atrous convolution\n",
    "        if output_stride == 16:\n",
    "            resnet.layer4[0].conv2.stride = (1, 1)\n",
    "            resnet.layer4[0].downsample[0].stride = (1, 1)\n",
    "            for block in resnet.layer4:\n",
    "                block.conv2.dilation = (2, 2)\n",
    "                block.conv2.padding = (2, 2)\n",
    "        elif output_stride == 8:\n",
    "            for layer in [resnet.layer3, resnet.layer4]:\n",
    "                layer[0].conv2.stride = (1, 1)\n",
    "                layer[0].downsample[0].stride = (1, 1)\n",
    "                for block in layer:\n",
    "                    block.conv2.dilation = (2 if layer is resnet.layer4 else 4,)*2\n",
    "                    block.conv2.padding = (2 if layer is resnet.layer4 else 4,)*2\n",
    "        \n",
    "        self.low_level_features = nn.Sequential(\n",
    "            resnet.conv1, resnet.bn1, resnet.act1, resnet.maxpool, resnet.layer1\n",
    "        )\n",
    "        self.high_level_features = nn.Sequential(\n",
    "            resnet.layer2, resnet.layer3, resnet.layer4\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        low_level_feat = self.low_level_features(x)\n",
    "        return low_level_feat, self.high_level_features(low_level_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3ebbe0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepLabV3Plus(\n",
    "    backbone=ResNetBackbone(output_stride=16, pretrained=True, in_channels=4),\n",
    "    num_classes=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4c79e5ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 256, 256])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2, 4, 256, 256)\n",
    "y = model(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7186dab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5311b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 256, 256])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class UNetDownBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int):\n",
    "        super(UNetDownBlock, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            ConvBlock(in_channels, out_channels, batch_norm=True, activation='relu'),\n",
    "            ConvBlock(out_channels, out_channels, batch_norm=True, activation='relu')\n",
    "        )\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        skip_connection = self.conv(x)\n",
    "        pooled_output = self.pool(skip_connection)\n",
    "        return pooled_output, skip_connection\n",
    "\n",
    "class UNetUpBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int):\n",
    "        super(UNetUpBlock, self).__init__()\n",
    "        \n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            ConvBlock(in_channels + out_channels, out_channels, batch_norm=True, activation='relu'),\n",
    "            ConvBlock(out_channels, out_channels, batch_norm=True, activation='relu')\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor, skip_connection: torch.Tensor) -> torch.Tensor:\n",
    "        x_upsampled = F.interpolate(x, size=skip_connection.shape[2:], mode='bilinear', align_corners=False)\n",
    "        x_concat = torch.cat((skip_connection, x_upsampled), dim=1)\n",
    "        return self.conv(x_concat)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, \n",
    "        in_channels: int=4, \n",
    "        num_classes: int=8, \n",
    "        channel_widths: list[int]=[64, 128, 256, 512, 1024],\n",
    "        activation: bool=True\n",
    "    ):\n",
    "        \n",
    "        super(UNet, self).__init__()\n",
    "        \n",
    "        self.in_channels = in_channels\n",
    "        self.num_classes = num_classes\n",
    "        self.channel_widths = channel_widths\n",
    "\n",
    "        self.encoder_blocks = nn.ModuleList([\n",
    "            UNetDownBlock(in_channels if i == 0 else channel_widths[i-1], channel_widths[i]) for i in range(4)\n",
    "        ])\n",
    "        \n",
    "        self.bottleneck = nn.Sequential(\n",
    "            ConvBlock(channel_widths[3], channel_widths[4], batch_norm=True, activation='relu'),\n",
    "            ConvBlock(channel_widths[4], channel_widths[4], batch_norm=True, activation='relu')\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.decoder_blocks = nn.ModuleList([\n",
    "            UNetUpBlock(channel_widths[i], channel_widths[i-1]) for i in range(4, 0, -1)\n",
    "        ])\n",
    "        \n",
    "        self.classifier = nn.Conv2d(channel_widths[0], num_classes, kernel_size=1)\n",
    "        if num_classes == 1 and activation:\n",
    "            self.activation = nn.Sigmoid()\n",
    "        elif activation:\n",
    "            self.activation = nn.Softmax(dim=1)\n",
    "        else:\n",
    "            self.activation = nn.Identity()\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        skip_connections = []\n",
    "        for block in self.encoder_blocks:\n",
    "            x, s = block(x)\n",
    "            skip_connections.append(s)\n",
    "        \n",
    "        x = self.bottleneck(x)\n",
    "        \n",
    "        for block in self.decoder_blocks:\n",
    "            x = block(x, skip_connections.pop()) \n",
    "        \n",
    "        x = self.classifier(x)\n",
    "        return self.activation(x)\n",
    "\n",
    "unet = UNet(in_channels=4, num_classes=5)\n",
    "x = torch.randn(2, 4, 256, 256)\n",
    "y_unet = unet(x)\n",
    "y_unet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "23f4838b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters in UNet: 31385669\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in unet.parameters())\n",
    "print(f'Total parameters in UNet: {total_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "830dffbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from segmentation_models_pytorch import Segformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5826f6ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45897afd5cdf4e37939e769e225ca6ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/135 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdc4a58a691345619ad819e39fb6c3cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/328M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Segformer(\n",
    "    encoder_name=\"mit_b5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "737abc74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters in Segformer mit_b5: 81969089\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'Total parameters in Segformer mit_b5: {total_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d333741",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "gdf = gpd.read_parquet('../data/cpb_lc/samples.par')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c940d4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "geometry     geometry\n",
       "id             object\n",
       "year            int64\n",
       "state          object\n",
       "naip_path      object\n",
       "s2_path        object\n",
       "lc_path        object\n",
       "split          object\n",
       "fold            int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf.dtypes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
